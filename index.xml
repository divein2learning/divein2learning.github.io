<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>深度学习的那些事儿</title>
    <link>https://divein2learning.github.io/</link>
    <description>Recent content on 深度学习的那些事儿</description>
    <image>
      <title>深度学习的那些事儿</title>
      <url>https://divein2learning.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://divein2learning.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 04 Mar 2023 08:16:26 +0800</lastBuildDate><atom:link href="https://divein2learning.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>你或许需要知道的深度学习那些事儿</title>
      <link>https://divein2learning.github.io/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%AF%86/</link>
      <pubDate>Sat, 04 Mar 2023 08:16:26 +0800</pubDate>
      
      <guid>https://divein2learning.github.io/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%AF%86/</guid>
      <description>如何理解深度学习 大家都听说过AlphaGo这个小玩意吧，从它战胜李世石后，AI的热度一度上涨，也就让大家好奇这背后的技术究竟是什么，能够在围棋这个充满挑战的任务中完成屠榜。 这背后就是深度学习，那么这个深度学习实际又是什么呢？是神经网络？或是古老的RBM进化而来的现代学术产物？实际上，就我看来，深度学习是一个领域，可以说是一个学科，maybe类似于物理，是为了试着解释一些事物背后的逻辑而产生的“学科”，这里所谓的事物，其实就是数据之间的联系，如果在两组数据之间构建联系，这是很早人们就开始探究的问题。只是，到21世纪，一些相对比较简单的联系，已被统计学家解释清楚，比如能够从数据中模拟它背后的分布，再用分布之间的关系来串联数据本身的关系。 除了最基本的统计学带来的推动，还有以梯度提升树为代表的传统机器学习，使得一些从统计理论上无法解释透彻的关系，有了新的突破，且已被证明对于许多表格数据，树模型有着超越其他模型的性能。那么到此为止，最为常见的表格数据就有了非常优秀的工具能够用来寻找数据内部的联系。 但是，在我们的日常生活中，表格不是数据的全部，网页上的图片，以及现在你看到的这篇博文，都是由数据构成的。你能够在电脑上看见的，以及看不见的，所有都是数据。只是呈现给了我们一种人类方便阅读方便理解的形式。而这些非表格数据，即所谓的非结构数据，往往是更多的，甚至于表格数据对于所有的这些数据来讲，仅仅是冰山一角，沧海一粟。因此传统机器学习解决的只是数据家族中的一小部分，有更多的数据等着被利用起来。这就有了大家听说的神经网络。 什么又是神经网络 所谓的神经网络，就是为了描述数据之间关系产生的一种工具，只是这里的数据指的是图片，文本，这类人们习以为常的，直觉上跟阿拉伯数字没有关系的数据，本质上想要解决的问题，跟传统机器学习没有差别。只是这个工具有些高级，有些fancy。
一些（或许）重要的模型 从早期的LeNet到VGG再到后来的ResNet，里程碑式的将图像分类这个基本问题的精度达到了与人类的水平相当。从RCNN到Faster-RCNN再到YOLO系列，以及近两年的DETR，将目标检测的精度和速度又拔高到了新的高度。
在文本领域NLP中，从简单RNN到加入LSTM单元的RNN再到现在无人不知无人不晓的Transformer架构的提出，极大的推动了NLP领域的发展（参考ChatGPT的爆火），甚至Transformer出圈到CV领域，从ViT到Swin-Transformer，模型的精度甚至超过ResNet这一类几年前的SOTA模型，非常让人震撼。 因此有人就觉得，Transformer的架构应该作为基本模型架构，打通CV和NLP，解决多模态（multimodal）任务，OpenAI提出的CLIP又是一枚炸弹，能够实现文本与图像之间信息的交互，使得图像分类不受限于预先设定的类别，能够更客制化输出。
还有最近比较火的AI绘画，之前OpenAI提出的DALL·E2和现在Stable Diffusion，效果非常炸裂。 最后想说的一点 深度学习领域的发展越来越快，或许下个月，下个星期，又有新的模型爆火，而在这些outstanding的模型背后，是用超多的算力（money）和硬件（还是money）支撑起来的，所以很多效果炸裂的模型，我们或许一辈子只有尝试的权力（本质还是没钱），就算开源训练代码也没法重现结果（除非有人开源模型训练之后的参数和模型架构，也就是预训练模型），因此，Hugging Face是个值得我们大多数人去看看的地方，那里有非常多的模型供你下载使用。那么，今天就到这里吧~（累了累了）</description>
    </item>
    
    
  </channel>
</rss>
